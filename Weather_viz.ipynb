{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "from distributed import Client\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import hvplot.xarray  # noqa: adds hvplot method to xarray objects\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import s3fs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"<style>\n",
    "@media (min-width: 1200px) {\n",
    "  .container {\n",
    "    width: 98%;\n",
    "  }\n",
    "}\n",
    "\n",
    "div.output_subarea{padding:.4em .4em 0 .4em;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1;max-width:100%}\n",
    ".bk-input {background-color:blue}\n",
    "</style>\n",
    "<script>\n",
    "    $('#appmode-leave').hide();                          // Hides the edit app button.\n",
    "    $('#appmode-busy').hide();                           // Hides the kernel busy indicator.\n",
    "    $('#appmode-loader').append('<h2>Loading...</h2>');  // Adds a loading message.\n",
    ";</script>\n",
    "\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlngbox = [-82, -74, 44.5, 49]\n",
    "climatic_period = ['1981-01-01', '2010-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 's3://cires-20-century-reanalysis-v3/zarr/single-levels-space'\n",
    "storage_options = {'endpoint_url': 'https://s3.us-east-1.wasabisys.com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(fsspec.get_mapper(bucket,\n",
    "                                    client_kwargs=storage_options,\n",
    "                                    anon=True),\n",
    "                  consolidated=True)\n",
    "# ds = xr.open_zarr('/home/slanglois/Documents/store/final/target.zarr',\n",
    "#                   consolidated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '1979-09-25'\n",
    "start_date = (datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "ds_ls_sliced = ds.sel(time=slice(start_date, end_date)).load()\n",
    "\n",
    "\n",
    "ds_sliced = ds_ls_sliced.sel(longitude=slice(latlngbox[0], latlngbox[1]),\n",
    "                             latitude=slice(latlngbox[2], latlngbox[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_values = ds_sliced['prate'].max('time')\n",
    "df_da = da_values.to_dataframe().reset_index()\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df_da, geometry=gpd.points_from_xy(df_da.longitude, df_da.latitude))\n",
    "gdf.crs = 4326\n",
    "gdf = gdf.to_crs(3857)\n",
    "gdf['longitude'] = gdf.geometry.x\n",
    "gdf['latitude'] = gdf.geometry.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruled-based algorithm\n",
    "\n",
    "def preliminary_type(ds_rolling_sl,\n",
    "                     ds_rolling_pl):\n",
    "\n",
    "\n",
    "    # 1. 0.12 < Precipitation rate <= 0.5 and CAPE < 500\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate <= 0.5/3600, ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_sl.prate >0.12/3600, a)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 40, -1)\n",
    "\n",
    "    # 2. 0.12 < Precipitation rate <= 0.5 and CAPE >= 500\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate <= 0.5/3600, ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_sl.prate >0.12/3600, a)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 40, da)\n",
    "\n",
    "    # 3. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 30, da)\n",
    "\n",
    "    # 4. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 33, da)\n",
    "\n",
    "    # 5. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 10, da)\n",
    "\n",
    "    # 6. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 13, da)\n",
    "\n",
    "    # 7. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 60, da)\n",
    "\n",
    "    # 8. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 63, da)\n",
    "\n",
    "    # 9. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 60, da)\n",
    "\n",
    "    # 10. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 63, da)\n",
    "\n",
    "    # 10. Precipitation rate <0.12\n",
    "    da = xr.where(ds_rolling_sl.prate<=0.12/3600, 99, da)\n",
    "    return pd.DataFrame(da.values[::-1,:])\n",
    "\n",
    "def preliminary_type_da(ds_rolling_sl,\n",
    "                        ds_rolling_pl):\n",
    "\n",
    "\n",
    "    # 1. 0.12 < Precipitation rate <= 0.5 and CAPE < 500\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate <= 0.5/3600, ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_sl.prate >0.12/3600, a)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 40, -1)\n",
    "\n",
    "    # 2. 0.12 < Precipitation rate <= 0.5 and CAPE >= 500\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate <= 0.5/3600, ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_sl.prate >0.12/3600, a)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 40, da)\n",
    "\n",
    "    # 3. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 30, da)\n",
    "\n",
    "    # 4. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 33, da)\n",
    "\n",
    "    # 5. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 10, da)\n",
    "\n",
    "    # 6. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 13, da)\n",
    "\n",
    "    # 7. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 60, da)\n",
    "\n",
    "    # 8. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient <=9.5, 900 mb Pressure gradient >= 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500<=9.5 ,ds_rolling_pl.gradh900>=8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 63, da)\n",
    "\n",
    "    # 9. Precipitation rate > 0.5, CAPE < 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape<500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 60, da)\n",
    "\n",
    "    # 10. Precipitation rate > 0.5, CAPE >= 500, 500mb Pressure gradient >9.5, 900 mb Pressure gradient < 8\n",
    "    a = xr.ufuncs.logical_and(ds_rolling_sl.prate>0.5/3600 ,ds_rolling_sl.cape>=500)\n",
    "    b = xr.ufuncs.logical_and(ds_rolling_pl.gradh500>9.5 ,ds_rolling_pl.gradh900<8)\n",
    "    c = xr.ufuncs.logical_and(a,b)\n",
    "    da = xr.where(c, 63, da)\n",
    "\n",
    "    # 10. Precipitation rate <0.12\n",
    "    da = xr.where(ds_rolling_sl.prate<=0.12/3600, 99, da)\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find important storms\n",
    "\n",
    "\n",
    "# Compute preliminary storm type and add to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 's3://cires-20-century-reanalysis-v3/zarr/pressure-levels-space'\n",
    "\n",
    "storage_options = {'endpoint_url': 'https://s3.us-east-1.wasabisys.com'}\n",
    "\n",
    "# ds_pl = xr.open_zarr('/home/slanglois/Documents/store/pressure/final/target.zarr', consolidated=True)\n",
    "\n",
    "ds_pl = xr.open_zarr(fsspec.get_mapper(bucket,\n",
    "                                    client_kwargs=storage_options,\n",
    "                                    anon=True),\n",
    "                     consolidated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ls_pl_sliced = ds_pl.sel(level=[500,900], time=slice(start_date, end_date)).load()\n",
    "\n",
    "level = 500\n",
    "variable = 'gradh500'\n",
    "\n",
    "da = np.sqrt(np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('longitude')) + \n",
    "             np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('latitude')))\n",
    "ds_ls_pl_sliced[variable] = da\n",
    "\n",
    "level = 900\n",
    "variable = 'gradh900'\n",
    "\n",
    "da = np.sqrt(np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('longitude')) + \n",
    "             np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('latitude')))\n",
    "ds_ls_pl_sliced[variable] = da\n",
    "\n",
    "ds_pl_sliced = ds_ls_pl_sliced.sel(longitude=slice(latlngbox[0], latlngbox[1]),\n",
    "                             latitude=slice(latlngbox[2], latlngbox[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preliminary_type(ds_sliced.max('time'),\n",
    "                      ds_pl_sliced.max('time'))\n",
    "\n",
    "ds_sliced['prelim_type'] = preliminary_type_da(ds_sliced.max('time'),\n",
    "                                               ds_pl_sliced.max('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_code = [10, 13, 30, 33, 40, 43, 60, 63, 99]\n",
    "gspec = pn.GridSpec(sizing_mode='stretch_both', height=100)\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True,\n",
    "                       client_kwargs= {'endpoint_url': 'https://s3.us-east-2.wasabisys.com'})\n",
    "\n",
    "for x in range(0,5):\n",
    "    for y in range(0,9):\n",
    "        gspec[x, y] = pn.widgets.Select(value=10, options=numerical_code, max_height=25, max_width=50,\n",
    "                                        margin=(0,0,0,0), background='black')\n",
    "        \n",
    "# look for a storm type calculated by meteorologist\n",
    "filename = 's3://analytics-store/manual_storm_types/{}.csv'.format(end_date)\n",
    "if fs.exists(filename):\n",
    "    with fs.open(filename) as f:\n",
    "        df = pd.read_csv(f)\n",
    "        for i in range(0,5):\n",
    "            for j in range(0,9):\n",
    "                gspec[i, j].value = df.iloc[i,j]\n",
    "\n",
    "# if empty, plot preliminary storm type\n",
    "else:\n",
    "    df = preliminary_type(ds_sliced.max('time'),\n",
    "                          ds_pl_sliced.max('time'))\n",
    "    for i in range(0,5):\n",
    "        for j in range(0,9):\n",
    "            gspec[i, j].value = df.iloc[i,j]   \n",
    "\n",
    "def plot_variable_ls(ds, ds_ls, variable, gdf, title, numbers, shared):\n",
    "    da_values = ds[variable]\n",
    "    \n",
    "        \n",
    "    if variable == 'prelim_type':\n",
    "        da_values_ls = ds_ls['tcdc']\n",
    "    else:\n",
    "        da_values_ls = ds_ls[variable]\n",
    "        \n",
    "    precise = False\n",
    "    \n",
    "    if variable == 'prate':\n",
    "        da_values = da_values*3600\n",
    "        da_values_ls = da_values_ls*3600\n",
    "        precise = True\n",
    "    elif variable =='tmax' or variable=='tmin':\n",
    "        da_values = da_values - 273.15\n",
    "        da_values_ls = da_values_ls - 273.15\n",
    "    \n",
    "\n",
    "    # \n",
    "    df_da = da_values.to_dataframe().reset_index()\n",
    "    \n",
    "    if precise==True:\n",
    "        labels = hv.Labels({('x', 'y'): gdf[['longitude','latitude']],\n",
    "                            'text': ['{0:.1f}'.format(i) for i in df_da[variable]]},\n",
    "                                                   ['x', 'y'], 'text') \n",
    "    else:\n",
    "        labels = hv.Labels({('x', 'y'): gdf[['longitude','latitude']],\n",
    "                            'text': ['{0:.0f}'.format(i) for i in df_da[variable]]},\n",
    "                                                   ['x', 'y'], 'text') \n",
    "    clim = (da_values_ls.min().values, da_values_ls.max().values)\n",
    "    # \n",
    "    jet = cm.get_cmap('jet', 256)\n",
    "    newcolors = jet(np.linspace(0, 1, 256))\n",
    "    newcolors[75, :] = [0.9,0.9,0.9,0]\n",
    "#     newcolors[0, :] = [0.9,0.9,0.9,0]\n",
    "    cmap = ListedColormap(newcolors[75:225, :])\n",
    "#     cmap = ListedColormap(newcolors)\n",
    "    \n",
    "    grid_plot = da_values.hvplot(x='longitude', y='latitude', \n",
    "                                 cmap=cmap,\n",
    "                                 title=title,\n",
    "                                 clim=clim,\n",
    "                                 alpha=0.9,\n",
    "                                 geo=True)\n",
    "\n",
    "    shared_axes = shared.value\n",
    "    display_number = numbers.value\n",
    "    \n",
    "    xlim=(-84, -72)\n",
    "    ylim=(44,50)\n",
    "    \n",
    "    if variable == 'hgt':\n",
    "        display_number = False\n",
    "        xlim=(-98, -50)\n",
    "        ylim=(39,64)\n",
    "    \n",
    "    alpha = 0.65\n",
    "    if variable == 'prelim_type':\n",
    "        alpha = 0\n",
    "    contourf_plot = da_values_ls.hvplot.contourf(levels=10,\n",
    "                                                 geo=True,\n",
    "                                                 hover=True,\n",
    "                                                 clim=clim,\n",
    "                                                 alpha=alpha,\n",
    "                                                 cmap=cmap,\n",
    "                                                 xlim=xlim,\n",
    "                                                 ylim=ylim,\n",
    "                                                 width=525,\n",
    "                                                 height=250,\n",
    "                                                 tiles='ESRI')\n",
    "    # \n",
    "#     contour_plot = da_values_ls.hvplot.contour(levels=20,\n",
    "#                                                geo=True,\n",
    "#                                                clim=clim,\n",
    "#                                                xlim=(-84, -72),\n",
    "#                                                ylim=(44,50),\n",
    "#                                                alpha=1,\n",
    "#                                                cmap='isolum')\n",
    "    \n",
    "    # \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    if display_number is True:\n",
    "        overlay =  (contourf_plot*grid_plot*labels).opts(active_tools=['wheel_zoom','pan'],\n",
    "                                                         toolbar = None,\n",
    "                                                         shared_axes=shared_axes)\n",
    "    else:\n",
    "        overlay =  (contourf_plot*grid_plot).opts(active_tools=['wheel_zoom','pan'],\n",
    "                                                  toolbar = None,\n",
    "                                                  shared_axes=shared_axes)\n",
    "    \n",
    "        \n",
    "    overlay.opts(\n",
    "        opts.Labels(text_font_size='8.5pt', text_font_style='bold'))\n",
    "    return overlay\n",
    "\n",
    "# Replace by important storms\n",
    "options=['Temps sec : 1979-09-23 - 1979-09-25',\n",
    "                               'Tempête #1 : 1979-09-18 - 1979-09-20']\n",
    "\n",
    "dates = '1979-09-23 - 1979-09-25'\n",
    "\n",
    "x = pn.widgets.Select(value=options[0], \n",
    "                      options=options, \n",
    "                      name='# de tempête')\n",
    "progress = pn.widgets.Progress(name='Progress', value=0, width=200)\n",
    "\n",
    "numbers = pn.widgets.Checkbox(name='Display numbers', value=True)\n",
    "shared = pn.widgets.Checkbox(name='Shared axis', value=False)\n",
    "\n",
    "layout = pn.Column(\n",
    "            pn.Row('## Weather Vizualisation (72h window)', pn.Column(x, progress, pn.Row(numbers, shared)),\n",
    "                   pn.Column(gspec, sizing_mode='stretch_width')),\n",
    "                pn.Row(\n",
    "                plot_variable_ls(ds_sliced.max('time'), ds_ls_sliced.max('time'), 'cape', gdf, \n",
    "                                 '{} : maximum CAPE (J/kg)'.format(dates), numbers, shared),\n",
    "                plot_variable_ls(ds_sliced.max('time'), ds_ls_sliced.max('time'), 'prate', gdf,\n",
    "                                 '{} : maximum precipitation rate (mm/h)'.format(dates), numbers, shared),\n",
    "                plot_variable_ls(ds_sliced.max('time'), ds_ls_sliced.max('time'), 'pr_wtr', gdf,\n",
    "                                 '{} : maximum precipitable water (mm)'.format(dates), numbers, shared)\n",
    "                ),\n",
    "            pn.Row(\n",
    "                plot_variable_ls(ds_sliced.max('time'), ds_ls_sliced.max('time'), 'tcdc', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : maximum cloud cover (%)', numbers, shared),\n",
    "                plot_variable_ls(ds_pl_sliced.max('time'), ds_ls_pl_sliced.max('time'), 'gradh500', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : maximum 500-mb gradients (m/°)', numbers, shared)\n",
    "                ,\n",
    "                plot_variable_ls(ds_pl_sliced.max('time'), ds_ls_pl_sliced.max('time'), 'gradh900', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : maximum 900-mb gradients (m/°)', numbers, shared)\n",
    "                ),\n",
    "                pn.Row(\n",
    "                plot_variable_ls(ds_sliced, ds_ls_sliced.max('time'), 'prelim_type', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : preliminary storm type', numbers, shared),\n",
    "                plot_variable_ls(ds_pl_sliced.max('time').sel(level=500), ds_ls_pl_sliced.max('time').sel(level=500), 'hgt', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : maximum 500-mb height (m)', numbers, shared)\n",
    "                ,\n",
    "                plot_variable_ls(ds_pl_sliced.max('time').sel(level=900), ds_ls_pl_sliced.max('time').sel(level=900), 'hgt', gdf,\n",
    "                                 '1979-09-13 - 1979-09-15 : maximum 900-mb height (m)', numbers, shared)\n",
    "                )\n",
    "            \n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update(event):\n",
    "    end_date = x.value.split(' - ')[-1]\n",
    "    start_date = (datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "    progress.value = 5\n",
    "    ds_ls_sliced = ds.sel(time=slice(start_date,end_date)).load()\n",
    "    progress.value = 15\n",
    "    ds_ls_pl_sliced = ds_pl.sel(level=[500,900], time=slice(start_date,end_date)).load()\n",
    "    progress.value = 25\n",
    "    ###\n",
    "    ds_sliced = ds_ls_sliced.sel(longitude=slice(latlngbox[0], latlngbox[1]),\n",
    "                                 latitude=slice(latlngbox[2], latlngbox[3]))\n",
    "    level = 500\n",
    "    variable = 'gradh500'\n",
    "    da = np.sqrt(np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('longitude')) + \n",
    "                 np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('latitude')))\n",
    "    ds_ls_pl_sliced[variable] = da\n",
    "\n",
    "    level = 900\n",
    "    variable = 'gradh900'\n",
    "    da = np.sqrt(np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('longitude')) + \n",
    "                 np.square(ds_ls_pl_sliced.sel(level=level).hgt.differentiate('latitude')))\n",
    "    ds_ls_pl_sliced[variable] = da\n",
    "    \n",
    "    ds_pl_sliced = ds_ls_pl_sliced.sel(longitude=slice(latlngbox[0], latlngbox[1]),\n",
    "                                 latitude=slice(latlngbox[2], latlngbox[3]))\n",
    "    \n",
    "    ds_sliced['prelim_type'] = preliminary_type_da(ds_sliced.max('time'),\n",
    "                                               ds_pl_sliced.max('time'))\n",
    "    \n",
    "    variables = {'cape': ['cape', ds_sliced.max('time'), ds_ls_sliced.max('time'), 'maximum CAPE (J/kg)'],\n",
    "                 'prate': ['prate', ds_sliced.max('time'), ds_ls_sliced.max('time'),'maximum precipitation rate (mm/h)'],\n",
    "                 'pr_wtr' : ['pr_wtr', ds_sliced.max('time'), ds_ls_sliced.max('time'),'maximum precipitable water (mm)'],\n",
    "                 'tcdc': ['tcdc', ds_sliced.max('time'), ds_ls_sliced.max('time'), 'maximum cloud cover (%)'],\n",
    "                 'gradh500': ['gradh500', ds_pl_sliced.max('time'), ds_ls_pl_sliced.max('time'), 'maximum 500-mb gradients (m/°)'],\n",
    "                 'gradh900': ['gradh900', ds_pl_sliced.max('time'), ds_ls_pl_sliced.max('time'), 'maximum 900-mb gradients (m/°)'],\n",
    "                 'prelim_type': ['prelim_type', ds_sliced, ds_ls_sliced.max('time'), 'preliminary storm type'],\n",
    "                 'hgt': ['hgt', ds_pl_sliced.max('time').sel(level=500), ds_ls_pl_sliced.max('time').sel(level=500), 'maximum 500-mb height (m)'],\n",
    "                 'hgt2': ['hgt', ds_pl_sliced.max('time').sel(level=900), ds_ls_pl_sliced.max('time').sel(level=900), 'maximum 900-mb height (m)']}\n",
    "    \n",
    "    \n",
    "    for i, (key, value) in enumerate(variables.items()):  \n",
    "        layout[int(np.ceil((i+1)/3))][i - int(np.floor(i/3))*3].object = plot_variable_ls(value[1], value[2],\n",
    "                                                 value[0], gdf, '{} - {} : {}'.format(start_date, end_date, value[3]), numbers, shared )\n",
    "        if progress.value<=95:\n",
    "            progress.value = progress.value + 5\n",
    "\n",
    "    # look for a storm type calculated by meteorologist\n",
    "    filename = 's3://analytics-store/manual_storm_types/{}.csv'.format(end_date)\n",
    "    if fs.exists(filename):\n",
    "        with fs.open(filename) as f:\n",
    "            df = pd.read_csv(f)\n",
    "            for i in range(0,5):\n",
    "                if progress.value<=94:\n",
    "                    progress.value = progress.value + 6\n",
    "                for j in range(0,9):\n",
    "                    gspec[i, j].value = df.iloc[i,j]\n",
    "                    \n",
    "                \n",
    "    # if empty, plot preliminary storm type\n",
    "    else:\n",
    "        df = preliminary_type(ds_sliced.max('time'),\n",
    "                              ds_pl_sliced.max('time'))\n",
    "        for i in range(0,5):\n",
    "            if progress.value<=94:\n",
    "                progress.value = progress.value + 6\n",
    "            for j in range(0,9):\n",
    "                gspec[i, j].value = df.iloc[i,j] \n",
    "                \n",
    "    progress.value = 0\n",
    "    \n",
    "    # TODO : Calculate preliminary storm type and replace code above\n",
    "\n",
    "\n",
    "\n",
    "def update2(event):\n",
    "    end_date = layout[0][1][0].value.split(' - ')[-1]\n",
    "    arr = np.zeros([6,10])\n",
    "    for i in range(0,5):\n",
    "        for j in range(0,9):\n",
    "            arr[i,j] = gspec[i, j].value\n",
    "    with fs.open('s3://analytics-store/manual_storm_types/{}.csv'.format(end_date), 'w') as f:\n",
    "        pd.DataFrame(arr).to_csv(f, index=False)\n",
    "\n",
    "# def update2(event):\n",
    "#     print('test')\n",
    "\n",
    "x.param.watch(update, 'value')\n",
    "numbers.param.watch(update, 'value')\n",
    "shared.param.watch(update, 'value')\n",
    "\n",
    "for i in range(0,5):\n",
    "    for j in range(0,9):\n",
    "        gspec[i, j].param.watch(update2, 'value')\n",
    "\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storms",
   "language": "python",
   "name": "storms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
